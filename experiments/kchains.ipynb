{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propogating geometric information: $k$-chains\n",
    "\n",
    "*Background:*\n",
    "In geometric GNNs, **geometric information**, such as the relative orientation of local neighbourhoods, is propogated via summing features from multiple layers in fixed dimensional spaces. \n",
    "The ideal architecture can be run for any number of layers to perfectly propogate geometric information without loss of information.\n",
    "In practice, stacking geometric GNN layers may lead to distortion or **loss of information from distant nodes**.\n",
    "\n",
    "*Experiment:*\n",
    "To study the practical implications of depth in propagating geometric information beyond local neighbourhoods, we consider **$k$-chain geometric graphs** which generalise the examples from [SchÃ¼tt et al., 2021](https://arxiv.org/abs/2102.03150). \n",
    "Each pair of $k$-chains consists of $k+2$ nodes with $k$ nodes arranged in a line and differentiated by the orientation of the $2$ end points.\n",
    "Thus, $k$-chain graphs are $(\\lfloor \\frac{k}{2} \\rfloor + 1)$-hop distinguishable, and $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ geometric GNN iterations should be theoretically sufficient to distinguish them.\n",
    "In this notebook, we train equivariant and invariant geometric GNNs with an increasing number of layers to distinguish $k$-chains.\n",
    "\n",
    "![k-chains](fig/kchains.png)\n",
    "\n",
    "*Results:*\n",
    "- Despite the supposed simplicity of the task, especially for small chain lengths, we find that popular equivariant GNNs such as E-GNN and TFN may require **more iterations** than theoretically sufficient.\n",
    "- Notably, as the length of the chain gets larger than $k=4$, all equivariant GNNs tended to lose performance and required more than $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ iterations to solve the task.\n",
    "- Invariant GNNs are **unable** to distinguish $k$-chains.\n",
    "\n",
    "These results points to preliminary evidence of the **oversquashing** phenomenon for geometric GNNs.\n",
    "These issues are most evident for E-GNN, which uses a single vector feature to aggregate and propogate geometric information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import is_undirected, to_undirected, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from functools import partial\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "print(\"e3nn version {}\".format(e3nn.__version__))\n",
    "\n",
    "from src.utils.plot_utils import plot_2d, plot_3d\n",
    "from src.utils.train_utils import run_experiment\n",
    "from src.models import MPNNModel, EGNNModel, GVPGNNModel, TFNModel, SchNetModel, DimeNetPPModel, MACEModel\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "# print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "# print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kchains(k):\n",
    "    assert k >= 2\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    # Graph 0\n",
    "    atoms = torch.LongTensor( [0] + [0] + [0]*(k-1) + [0] )\n",
    "    edge_index = torch.LongTensor( [ [i for i in range((k+2) - 1)], [i for i in range(1, k+2)] ] )\n",
    "    pos = torch.FloatTensor(\n",
    "        [[-4, -3, 0]] + \n",
    "        [[0, 5*i , 0] for i in range(k)] + \n",
    "        [[4, 5*(k-1) + 3, 0]]\n",
    "    )\n",
    "    center_of_mass = torch.mean(pos, dim=0)\n",
    "    pos = pos - center_of_mass\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "    \n",
    "    # Graph 1\n",
    "    atoms = torch.LongTensor( [0] + [0] + [0]*(k-1) + [0] )\n",
    "    edge_index = torch.LongTensor( [ [i for i in range((k+2) - 1)], [i for i in range(1, k+2)] ] )\n",
    "    pos = torch.FloatTensor(\n",
    "        [[4, -3, 0]] + \n",
    "        [[0, 5*i , 0] for i in range(k)] + \n",
    "        [[4, 5*(k-1) + 3, 0]]\n",
    "    )\n",
    "    center_of_mass = torch.mean(pos, dim=0)\n",
    "    pos = pos - center_of_mass\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_kchains(k=k)\n",
    "for data in dataset:\n",
    "    # plot_2d(data, lim=5*k)\n",
    "    plot_3d(data, lim=5*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "model_name = \"tfn\"\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "for num_layers in range(k // 2 , k + 3):\n",
    "\n",
    "    print(f\"\\nNumber of layers: {num_layers}\")\n",
    "    \n",
    "    model = {\n",
    "        \"mpnn\": MPNNModel,\n",
    "        \"schnet\": SchNetModel,\n",
    "        \"dimenet\": DimeNetPPModel,\n",
    "        \"egnn\": EGNNModel,\n",
    "        \"gvp\": GVPGNNModel,\n",
    "        \"tfn\": TFNModel,\n",
    "        \"mace\": partial(MACEModel, correlation=2),\n",
    "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "    \n",
    "    best_val_acc, test_acc, train_time = run_experiment(\n",
    "        model, \n",
    "        dataloader,\n",
    "        val_loader, \n",
    "        test_loader,\n",
    "        n_epochs=100,\n",
    "        n_times=10,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94aa676993820a604ac86f7af94f5432e989a749d5dd43e18f9507de2e8c2897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
